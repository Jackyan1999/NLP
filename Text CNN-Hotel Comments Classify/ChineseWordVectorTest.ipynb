{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "入住的是度假区的豪华海景房,前台给了5楼(最高6楼),然后差不多100%的海景,虽然是挂牌5星的,但是本人觉得是4星的标准,和我后来入住的5星喜来登差了蛮多的,不过整体来说还是符合他家的价钱的.\n"
     ]
    }
   ],
   "source": [
    "#获取训练语料\n",
    "import os\n",
    "\n",
    "neg_dir=r'comments/10000/neg'\n",
    "pos_dir=r'comments/10000/pos'\n",
    "\n",
    "texts=[]\n",
    "labels=[]\n",
    "\n",
    "for fname in os.listdir(pos_dir):\n",
    "    if(fname[-4:]=='.txt'):\n",
    "        f=open(os.path.join(pos_dir,fname),encoding='utf-8')\n",
    "        t=f.read()\n",
    "        texts.append(t.strip().replace('\\n',''))\n",
    "        f.close()\n",
    "        labels.append(1)\n",
    "for fname in os.listdir(neg_dir):\n",
    "    if(fname[-4:]=='.txt'):\n",
    "        f=open(os.path.join(neg_dir,fname),encoding='utf-8')\n",
    "        texts.append(f.read())\n",
    "        f.close()\n",
    "        labels.append(0)\n",
    "print(len(texts))\n",
    "print(texts[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2612\n",
      "八\n"
     ]
    }
   ],
   "source": [
    "#读取停用词\n",
    "with open('stopwords.txt', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "stop_words = [word.strip().replace('\\n', '') for word in words]\n",
    "print(len(stop_words))\n",
    "print(stop_words[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     5   179   185   179  1092   199     8  7055  1763\n",
      "  1391 17560  8784     8   202 17561  6125  7056  8785 17562   722 17563\n",
      "   899 17564 17565     8  1169    68    88   145  1710   739  3214  8786\n",
      "  2521  3412  1198   423  6126   194  1313  2409  1112    36    39  1429\n",
      "  5352  3998  1616   657  4825  8787   657   423  3649  7057   173  7058\n",
      "   683   657  1170    89   171  4358   488  5353 17566  7059   301   488\n",
      "   423  3649 10963 17567]\n"
     ]
    }
   ],
   "source": [
    "#文本预处理\n",
    "import jieba\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "MAX_WORDS=100000 #使用100000个词语\n",
    "MAX_LEN=100 #每条评论的长度\n",
    "\n",
    "\n",
    "#将句子分词并用空格隔开\n",
    "textList=[' '.join([w for w in jieba.cut(text) if w not in stop_words]) for text in texts]\n",
    "\n",
    "tokenizer=Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(texts=textList)\n",
    "sequences=tokenizer.texts_to_sequences(texts=textList)\n",
    "\n",
    "word_index=tokenizer.word_index\n",
    "\n",
    "data=pad_sequences(sequences=sequences,maxlen=MAX_LEN)\n",
    "labels=np.asarray(labels)\n",
    "print(data.shape)\n",
    "print(data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 100)\n",
      "(2000, 100)\n",
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "#划分训练集、验证集、测试集\n",
    "\n",
    "#各数据集数量\n",
    "TRAIN_SAMPLES=6000\n",
    "VALIDATION_SAMPLES=2000\n",
    "TEST_SAMPLES=2000\n",
    "\n",
    "#打乱数据集\n",
    "indices=np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data=data[indices]\n",
    "labels=labels[indices]\n",
    "\n",
    "x_train=data[:TRAIN_SAMPLES]\n",
    "y_train=labels[:TRAIN_SAMPLES]\n",
    "\n",
    "x_val=data[TRAIN_SAMPLES:TRAIN_SAMPLES+VALIDATION_SAMPLES]\n",
    "y_val=labels[TRAIN_SAMPLES:TRAIN_SAMPLES+VALIDATION_SAMPLES]\n",
    "\n",
    "x_test=data[TRAIN_SAMPLES+VALIDATION_SAMPLES:]\n",
    "y_test=labels[TRAIN_SAMPLES+VALIDATION_SAMPLES:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259837\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#解析词向量文件\n",
    "\n",
    "\n",
    "#映射字典，每个单词Key对应一个词向量\n",
    "embeddings_index={}\n",
    "\n",
    "f=open('sgns.zhihu.word',encoding='utf-8')\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]#第一个是单词\n",
    "    coefs=np.asarray(values[1:],dtype='float32')#后面都是系数\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()\n",
    "print(len(embeddings_index))\n",
    "print(len(embeddings_index['的']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 300)\n"
     ]
    }
   ],
   "source": [
    "#准备词向量矩阵\n",
    "\n",
    "EMBEDDING_DIM=300#词向量的长度\n",
    "\n",
    "embedding_matrix=np.zeros((MAX_WORDS,EMBEDDING_DIM))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    word_vector=embeddings_index.get(word)\n",
    "    if(word_vector is not None):#若是未登录词，则词向量为初始值0\n",
    "        embedding_matrix[i]=word_vector\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 300)          30000000  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               7680256   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,754,433\n",
      "Trainable params: 37,754,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#定义模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(MAX_WORDS,EMBEDDING_DIM,input_length=MAX_LEN))#词嵌入层\n",
    "#model.add(Conv1D(128,3,activation='relu'))\n",
    "#model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把词嵌入矩阵载入到词嵌入层中\n",
    "\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable=False#冻结\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "6000/6000 [==============================] - 1s 241us/step - loss: 2.0213 - acc: 0.8000 - val_loss: 0.4633 - val_acc: 0.8520\n",
      "Epoch 2/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 0.0162 - acc: 0.9977 - val_loss: 0.4887 - val_acc: 0.8585\n",
      "Epoch 3/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 0.0084 - acc: 0.9997 - val_loss: 0.5342 - val_acc: 0.8585\n",
      "Epoch 4/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 0.0047 - acc: 0.9998 - val_loss: 0.6200 - val_acc: 0.8570\n",
      "Epoch 5/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 0.0024 - acc: 0.9998 - val_loss: 0.7295 - val_acc: 0.8560\n",
      "Epoch 6/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.8004 - val_acc: 0.8580\n",
      "Epoch 7/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 8.2684e-04 - acc: 0.9998 - val_loss: 0.8675 - val_acc: 0.8575\n",
      "Epoch 8/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 5.7627e-04 - acc: 0.9998 - val_loss: 0.9368 - val_acc: 0.8550\n",
      "Epoch 9/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 4.3580e-04 - acc: 0.9998 - val_loss: 0.9974 - val_acc: 0.8555\n",
      "Epoch 10/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 3.5765e-04 - acc: 0.9998 - val_loss: 1.0510 - val_acc: 0.8545\n",
      "Epoch 11/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 3.0524e-04 - acc: 0.9998 - val_loss: 1.1006 - val_acc: 0.8545\n",
      "Epoch 12/50\n",
      "6000/6000 [==============================] - 0s 62us/step - loss: 2.8978e-04 - acc: 0.9997 - val_loss: 1.1343 - val_acc: 0.8545\n",
      "Epoch 13/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.7652e-04 - acc: 0.9998 - val_loss: 1.1678 - val_acc: 0.8540\n",
      "Epoch 14/50\n",
      "6000/6000 [==============================] - 0s 62us/step - loss: 2.6673e-04 - acc: 0.9997 - val_loss: 1.1959 - val_acc: 0.8540\n",
      "Epoch 15/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.5990e-04 - acc: 0.9998 - val_loss: 1.2200 - val_acc: 0.8535\n",
      "Epoch 16/50\n",
      "6000/6000 [==============================] - 0s 65us/step - loss: 2.5644e-04 - acc: 0.9997 - val_loss: 1.2424 - val_acc: 0.8540\n",
      "Epoch 17/50\n",
      "6000/6000 [==============================] - 0s 64us/step - loss: 2.5485e-04 - acc: 0.9997 - val_loss: 1.2651 - val_acc: 0.8520\n",
      "Epoch 18/50\n",
      "6000/6000 [==============================] - 0s 62us/step - loss: 2.5586e-04 - acc: 0.9998 - val_loss: 1.3021 - val_acc: 0.8565\n",
      "Epoch 19/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.5812e-04 - acc: 0.9998 - val_loss: 1.2940 - val_acc: 0.8540\n",
      "Epoch 20/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.5850e-04 - acc: 0.9997 - val_loss: 1.3609 - val_acc: 0.8560\n",
      "Epoch 21/50\n",
      "6000/6000 [==============================] - 0s 59us/step - loss: 2.7175 - acc: 0.7917 - val_loss: 1.3942 - val_acc: 0.7870\n",
      "Epoch 22/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 0.0698 - acc: 0.9807 - val_loss: 0.8346 - val_acc: 0.8555\n",
      "Epoch 23/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 0.0033 - acc: 0.9995 - val_loss: 0.8374 - val_acc: 0.8550\n",
      "Epoch 24/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.8455 - val_acc: 0.8545\n",
      "Epoch 25/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 8.5783e-04 - acc: 0.9998 - val_loss: 0.8594 - val_acc: 0.8535\n",
      "Epoch 26/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 6.7720e-04 - acc: 0.9998 - val_loss: 0.8773 - val_acc: 0.8550\n",
      "Epoch 27/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 5.2492e-04 - acc: 0.9998 - val_loss: 0.9261 - val_acc: 0.8545\n",
      "Epoch 28/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 4.0256e-04 - acc: 0.9998 - val_loss: 0.9780 - val_acc: 0.8540\n",
      "Epoch 29/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 3.5147e-04 - acc: 0.9998 - val_loss: 1.0262 - val_acc: 0.8540\n",
      "Epoch 30/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 3.1940e-04 - acc: 0.9998 - val_loss: 1.0674 - val_acc: 0.8545\n",
      "Epoch 31/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.9660e-04 - acc: 0.9998 - val_loss: 1.1085 - val_acc: 0.8570\n",
      "Epoch 32/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.8223e-04 - acc: 0.9998 - val_loss: 1.1421 - val_acc: 0.8560\n",
      "Epoch 33/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.7128e-04 - acc: 0.9997 - val_loss: 1.1724 - val_acc: 0.8560\n",
      "Epoch 34/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.6500e-04 - acc: 0.9997 - val_loss: 1.2006 - val_acc: 0.8560\n",
      "Epoch 35/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.5923e-04 - acc: 0.9998 - val_loss: 1.2274 - val_acc: 0.8555\n",
      "Epoch 36/50\n",
      "6000/6000 [==============================] - 0s 62us/step - loss: 2.5950e-04 - acc: 0.9997 - val_loss: 1.2512 - val_acc: 0.8545\n",
      "Epoch 37/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.5303e-04 - acc: 0.9998 - val_loss: 1.2735 - val_acc: 0.8540\n",
      "Epoch 38/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.5127e-04 - acc: 0.9998 - val_loss: 1.2934 - val_acc: 0.8545\n",
      "Epoch 39/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.5123e-04 - acc: 0.9998 - val_loss: 1.3119 - val_acc: 0.8545\n",
      "Epoch 40/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.4353e-04 - acc: 0.9998 - val_loss: 1.3316 - val_acc: 0.8530\n",
      "Epoch 41/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.4583e-04 - acc: 0.9998 - val_loss: 1.3509 - val_acc: 0.8545\n",
      "Epoch 42/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.4096e-04 - acc: 0.9998 - val_loss: 1.3675 - val_acc: 0.8555\n",
      "Epoch 43/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.4048e-04 - acc: 0.9998 - val_loss: 1.3816 - val_acc: 0.8550\n",
      "Epoch 44/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.3383e-04 - acc: 0.9998 - val_loss: 1.3973 - val_acc: 0.8545\n",
      "Epoch 45/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.4884e-04 - acc: 0.9997 - val_loss: 1.4154 - val_acc: 0.8480\n",
      "Epoch 46/50\n",
      "6000/6000 [==============================] - 0s 61us/step - loss: 2.3367e-04 - acc: 0.9998 - val_loss: 1.4192 - val_acc: 0.8535\n",
      "Epoch 47/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.3311e-04 - acc: 0.9998 - val_loss: 1.4300 - val_acc: 0.8530\n",
      "Epoch 48/50\n",
      "6000/6000 [==============================] - 0s 66us/step - loss: 2.4422e-04 - acc: 0.9998 - val_loss: 1.4351 - val_acc: 0.8540\n",
      "Epoch 49/50\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 2.3977e-04 - acc: 0.9998 - val_loss: 1.4506 - val_acc: 0.8515\n",
      "Epoch 50/50\n",
      "6000/6000 [==============================] - 0s 60us/step - loss: 2.4029e-04 - acc: 0.9998 - val_loss: 1.4518 - val_acc: 0.8540\n"
     ]
    }
   ],
   "source": [
    "#编译并训练模型\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "history=model.fit(x_train,y_train,epochs=50,batch_size=1024,validation_data=(x_val,y_val))\n",
    "model.save_weights('hotel_comments_classify.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 237us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2969743014619453, 0.8685]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试模型\n",
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
